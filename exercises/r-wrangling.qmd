---
title: "Importing and manipulating data with {{< fa brands r-project >}}"
echo: true
number-sections: true
---

::: {.badge}
<a href="https://datalab.sspcloud.fr/launcher/ide/rstudio?autoLaunch=false&networking.user.enabled=true&onyxia.friendlyName=%C2%ABrstudio-cours-ENS%C2%BB" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Test%20via%20SSP%20cloud%20-%20SSPCloud?logo=R&labelColor=black&color=%231965b8" alt="Onyxia"></a><br>
:::

<details>
<summary>
Check out the _slides_ below or [click here](/slides/wrangling.qmd)
to view the slides in full screen.
</summary>
``` {.yaml code-preview="/slides/wrangling.qmd"}
```

</details>

In this second tutorial,
we will learn to import and
manipulate data with
{{< fa brands r-project >}}. 

If you're interested in `Python` {{< fa brands python >}},
a very similar version of this tutorial is available in [my ENSAE course](https://pythonds.linogaliana.fr/content/manipulation/02b_pandas_TP.html).

::: {.callout-note}

Some code examples include annotations on the side,
hover over them to display them, as shown below
```{r}
#| echo: true
#| output: false
"an explanatory annotation accompanies me on the right" #<1>
```
1. I appear when you hover over me üê≠!

:::

In this chapter, we will mainly use the following packages
from the `tidyverse`: 

- `readr` for data import;
- `dplyr` for data manipulation.

::: {.callout-note}

The `tidyverse` is not the only complete ecosystem for data analysis.

However, for an introduction to {{< fa brands r-project >}}, it's 
certainly the most reasonable to adopt. 

Competing or complementary ecosystems
(`data.table`, `arrow`, `duckdb`) already require
a good understanding of the `tidyverse` and its limitations. 

:::

In this tutorial, we will use two data sources:

* Greenhouse gas emissions estimated at the municipal level by `ADEME`. The dataset is
available on [data.gouv](https://www.data.gouv.fr/fr/datasets/inventaire-de-gaz-a-effet-de-serre-territorialise/#_)
and directly queryable in {{< fa brands r-project >}} with
[this url](https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert) (this will be the subject of the first exercise)[^notedownload].
* Ideally, we would directly use the data
[available on the Insee website](https://www.insee.fr/fr/statistiques/3560121) but these require some
cleaning work that is beyond the scope of this tutorial. 
To facilitate importing Insee data, it's recommended to use the _packages_
[`doremifasol`](https://github.com/InseeFrLab/DoReMIFaSol) and [`insee`](https://github.com/pyr-opendatafr/R-Insee-Data) which simplify access to Insee data
available on the [insee.fr](https://www.insee.fr/fr/accueil) website
or via APIs. 

[^notedownload]: 

  `readr` offers the possibility to import data directly from a url. This is the option 
  taken in this tutorial. If you prefer, for 
  network access or performance reasons, to import from a local machine,
  you can download the data and change
  the import commands with the appropriate path instead of the url. 

# Preliminary steps: installing _packages_

{{< fa brands r-project >}} is an _open source_ language. Anyone can
therefore propose {{< fa brands r-project >}} code to increase the 
language's functionalities. A coherent set of functionalities is called
a __library__ or __package__. 

Since the team managing the {{< fa brands r-project >}} language doesn't intend
to integrate all libraries into the base language (which should
remain, as its name indicates, basic), there are
community spaces where people can make their _packages_ available. In
the {{< fa brands r-project >}} ecosystem, the two main ones[^bioconductor] are:

- The `CRAN` (_Comprehensive R Archive Network_): the official and historical repository
of {{< fa brands r-project >}} libraries.
To install a _package_ stored in this space, use `install.package`;
- `Github` {{< fa brands github >}}: the social network for _open source_ code. 
To install a _package_ stored in this space, use `remotes::install_github`[^remotes]

[^bioconductor]: There's also `bioconductor` but since it's mainly oriented towards biostatistics (one of the academic communities that adopted {{< fa brands r-project >}} earliest), we don't really use it

[^remotes]:
    `remotes::install_github` means to use the `install_github` function from the _package_ `remotes`. In other words, you need a _package_ to install other _packages_ ü§Ø.
    This is because `Github` didn't exist when {{< fa brands r-project >}} was created (1990s) and this functionality hasn't been added since. 

::: {.callout-note}

Generally, _packages_ with certain
maturity are on CRAN. `Github` has a more catch-all aspect where you find
gems alongside things of more variable quality. 

Some _packages_ we'll see aren't on CRAN because the validation procedure
to deposit your _package_ there is quite heavy and
tiring for volunteer developers, usually unpaid 
for this work and often doing it at night. 

:::

To install a package available on CRAN, for example
the [`dplyr`](https://dplyr.tidyverse.org/) package,
you can do:
```{r}
#| eval: false
#| echo: true
install.packages("insee")
```

To install a package available on `Github` {{< fa brands github >}},
for example [`doremifasol`](https://github.com/InseeFrLab/DoReMIFaSol)
which is available on the `InseeFrLab` account's repository, do:
```{r}
#| eval: false
#| echo: true
remotes::install_github('inseefrlab/DoReMIFaSol')
```

Here are all the instructions to install
the _packages_ needed to perform all
the exercises in this tutorial:
```{r}
#| echo: true
#| eval: false
install.packages(c("readr","dplyr", "tidyr", "ggplot2", "remotes"))
remotes::install_github('inseefrlab/DoReMIFaSol')
```

Since we'll frequently use `dplyr`, we can import it
directly:
```{r}
#| echo: true
#| output: false
library(dplyr)
library(tidyr)
library(stringr)
```

# Importing data

## Importing a csv from Ademe

To start, we'll import Ademe data using the
[`readr`](https://readr.tidyverse.org/) _package_[^readcsv]. 

::: {.callout-tip}
## Exercise 1: reading a csv with `readr` and observing the data

Here's the URL where the data is available
```{r}
#| echo: true
url <- "https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert"
```

1. Use the `readr` _package_ to import this data. Name this object `emissions`[^nomdf]
2. Display the first lines with `head` and observe the display difference with, for example,
this `dataframe`:
```{r}
#| echo: true
library(readr)
emissions <- read_csv(url)
```

3. Display the class of `emissions`. Do you now understand why this object is
slightly different from a base dataframe?
4. Use appropriate functions for the first 10 values, the last 15 and a random sample of 10 values using the [appropriate function from the `dplyr` package](https://dplyr.tidyverse.org/reference/sample_n.html)

<details>
<summary>
If stuck on question 1
</summary>
Read the `read_csv` documentation (very well done) or search for examples
online to discover this function.
‚ö†Ô∏è Don't use `read.csv` (base function) which isn't performant. 
</details>
:::

[^nomdf]: For lack of imagination, we're often tempted to call our
main _dataframe_ `df` or `data`. This is often a bad idea since
this name isn't very informative when rereading the code a few weeks
later. Self-documentation, an approach that consists of having code
that explains itself, is a good practice and it's therefore recommended
to give a simple but effective name to know the nature of the _dataset_ in question.

## First data manipulations

As mentioned
in [`utilitR`](https://www.book.utilitr.org/03_fiches_thematiques/fiche_tidyverse),
the main functions of `dplyr` (the _verbs_ of the `dplyr` grammar) 
are as follows:

- `select()`: select variables by their name;
- `rename()`: rename variables;
- `filter()`: select observations according to one or more conditions;
- `arrange()`: sort the table according to one or more variables;
- `mutate()`: add variables that are functions of other variables;
- `summarise()`: calculate a statistic from data;
- `group_by()`: perform operations by group.

```{ojs}
//| echo: false
viewof dplyrVerbs = Inputs.select(['select','rename','filter','mutate', 'arrange'], {value: "select"})
```

::: {#fig-verbs}
```{ojs}
//| echo: false
html`<img src="https://github.com/linogaliana/r-geographie/raw/main/exercises/img/${dplyrVerbs}.png" width="60%"</>`
```

Illustration of `dplyr` verbs

:::

The following _cheatsheet_ is very practical as it illustrates these different
functions. It's recommended to regularly
consult it (click on the image to zoom üîé):

::: {#cheatsheets-dplyr layout-ncol=2}

![](img/cheatsheet1.png)

![](img/cheatsheet2.png)

[`dplyr` _Cheatsheets_](https://dplyr.tidyverse.org/)
:::

::: {.callout-tip}
## Exercise 2: discovering `dplyr` verbs for data manipulation

First, let's familiarize ourselves with operations on
columns.

1. Create a _dataframe_ `emissions_copy` keeping only the columns
`INSEE commune`, `Commune`, `Autres transports` and `Autres transports international`

<details>
<summary>
Hint for this question
</summary>
![](https://github.com/linogaliana/r-geographie/raw/main/exercises/img/select.png)
</details>

2. Since variable names are impractical, rename them as
follows:
    + `INSEE commune` $\to$ `code_insee`
    + `Autres transports` $\to$ `transports`
    + `Autres transports international` $\to$ `transports_international`

<details>
<summary>
Hint for this question
</summary>
![](https://github.com/linogaliana/r-geographie/raw/main/exercises/img/rename.png)
</details>

3. To simplify, let's replace missing values (`NA`)
with the value 0[^na]. Use the
[`replace_na`](https://tidyr.tidyverse.org/reference/replace_na.html) function
from the _tidyr_ package, in conjunction with `mutate`,
to transform missing values to 0.

<details>
<summary>
Hint for this question
</summary>
![](https://github.com/linogaliana/r-geographie/raw/main/exercises/img/mutate.png)
</details>

4. Create the following variables in the same code sequence:
    - `dep`: the department. This can be created using the first two characters of `code_insee` with the `str_sub` function from the `stringr` _package_[^notecorse]
    - `transports_total`: transport sector emissions (sum of the two variables)

<details>
<summary>
Hint for this question
</summary>
![](https://github.com/linogaliana/r-geographie/raw/main/exercises/img/mutate.png)
</details>

5. Order the data from highest to lowest polluter
then order the data 
from highest to lowest polluter by department (from 01 to 95). 

<details>
<summary>
Hint for this question
</summary>
![](https://github.com/linogaliana/r-geographie/raw/main/exercises/img/arrange.png)
</details>

6. Calculate total emissions by department

<details>
<summary>
Hint for this question
</summary>

* _"Group by"_ = `group_by`
* _"total emissions"_ = `summarise(sum(***))`

</details>

:::

[^na]: This assumption is certainly false. It's exclusively
here to illustrate variable creation via `mutate`.

[^notecorse]: To be really precise, we would need to modify the values
obtained for Corsican departments with the `case_when` function
from the `dplyr` _package_. This is left as an additional exercise. 
```{r}
#| code-fold: true
#| code-summary: "Solution question 1"
emissions_copy <- emissions %>%
  select(`INSEE commune`, `Commune`, `Autres transports`, `Autres transports international`)
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 2"
emissions_copy <- emissions_copy %>%
  rename(
    code_insee = `INSEE commune`,
    transports = `Autres transports`,
    transports_international = `Autres transports international`
    )
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 3"
emissions_copy <- emissions_copy %>%
  mutate(
    transports = replace_na(transports),
    transports_international = replace_na(transports_international)
    )
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 4"
emissions_copy <- emissions_copy %>%
  mutate(
    dep = str_sub(code_insee, 1, 2),
    transports_total = transports + transports_international
    )
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 5"
emissions_copy %>%
  arrange(desc(transports_total))

emissions_copy %>%
  arrange(dep, desc(transports_total))
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 6"
emissions_copy %>%
  group_by(dep) %>%
  summarise(sum(transports_total))
```

## Importing Insee data

For our municipal information, we'll use one of Insee's
most used sources: [`Filosofi`](https://www.insee.fr/fr/metadonnees/source/serie/s1172) data. 
To facilitate retrieving these, we'll
use the community _package_ `doremifasol`:
```{r}
#| output: false
#| echo: true
library(doremifasol)
library(tibble)
filosofi <- as_tibble(
  telechargerDonnees("FILOSOFI_COM", date = 2016)
)
head(filosofi)
```

```{r}
#| echo: false
head(filosofi)
```

::: {.callout-note}
The `as_tibble` function converts the base _dataframe_ (`doremifasol` 
doesn't make assumptions about the manipulation ecosystem adopted) into 
a _dataframe_ adapted for use via the `tidyverse`. 
:::

# Data cleaning

:::{.callout-tip}
## Exercise 2

Since `readr` or `doremifasol` automatically
handled the data import, let's do a small
quality control:

1. Display the column names of our _dataframes_ `emissions` and `filosofi`. 
What are the common columns? Use the `intersect` function and understand
the nature of the problem.
2. Observe the structure of our datasets (column types). Are the default types appropriate?

Then, we verify the dimensions of the `DataFrames` and the structure of some key variables.
In this case, the fundamental variables for linking our data are the municipal variables.
Here, we have two geographic variables: a municipality code and a municipality name. 
We'll therefore verify they're well suited for statistical analysis.

3. Check the dimensions of the _dataframes_;
4. Check the number of unique values of geographic variables in each base. Do the results appear consistent?
5. Identify in `filosofi` the municipality names that correspond to multiple municipality codes and select their codes. In other words, identify the `CODGEO` such that there are duplicate `LIBGEO` and store them in a dataframe `duplicates`

We temporarily focus on observations where the label has more than two different municipality codes

6. Look at these observations in `filosofi`. For better visibility, reorder the obtained base alphabetically
7. Determine the average size (variable number of people: `NBPERSMENFISC16`) and some descriptive statistics of this data.
Compare to the same statistics on data where labels and municipality codes coincide
8. Check large cities (more than 100,000 people),
the proportion of cities for which the same name is associated with different municipality codes.
9. Check in `filosofi` the cities whose label equals Montreuil.
Also check those containing the term 'Saint-Denis'
```{r}
#| code-fold: true
#| code-summary: "Solution question 1"
#| output: false
str(emissions)
intersect(colnames(filosofi), colnames(emissions))
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 2"
#| output: false
str(filosofi)
str(emissions)
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 3"
#| output: false
dim(filosofi)
dim(emissions)
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 3"

emissions %>%
  select('INSEE commune', 'Commune') %>%
  summarize(Unique_Count = n_distinct(Commune))

filosofi %>%
  select('CODGEO', 'LIBGEO') %>%
  summarize(Unique_Count = n_distinct(LIBGEO))
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution questions 5 to 7"

# Question 5
duplicates <- filosofi %>%
  group_by(LIBGEO) %>%
  summarize(Count = n()) %>%
  select(LIBGEO, Count) %>%
  #arrange(desc(Count)) %>%
  filter(Count > 1)

# Question 6
filosofi %>%
  filter(LIBGEO %in% duplicates$LIBGEO) %>%
  arrange(LIBGEO)

# Question 7
filosofi %>%
  filter(LIBGEO %in% duplicates$LIBGEO) %>%
  summarize(Stats = mean(NBPERSMENFISC16, na.rm = TRUE))

# Calculate summary statistics for 'NBPERSMENFISC16' for rows where 'LIBGEO' is not in 'x$LIBGEO'
filosofi %>%
  filter(!(LIBGEO %in% duplicates$LIBGEO)) %>%
  summarize(Stats = mean(NBPERSMENFISC16, na.rm = TRUE))
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 8"

filosofi_big <- filosofi %>%
  filter(NBPERSMENFISC16 > 100000) %>%
  mutate(probleme = LIBGEO %in% duplicates$LIBGEO)

# Proportion of problematic cities
mean_probleme <- filosofi_big %>%
  summarize(mean(probleme))

# Filter rows where 'probleme' is TRUE
df_probleme <- filosofi_big %>%
  filter(probleme)
```

<details>
<summary>
What you should find in questions 8 and 9
</summary>

For question 8, you should get this:
```{r}
head(df_probleme)
```

While for question 9, your two _dataframes_ will look like
```{r}
#| code-fold: true
#| code-summary: "Solution question 9"
# Question 9
filosofi %>%
  filter(LIBGEO == 'Montreuil')

# Question 10
filosofi %>%
  filter(grepl('Saint-Denis', LIBGEO)) %>%
  head(10)
```
</details>

:::

This small exercise is reassuring because the duplicate labels
are actually identical municipality names that aren't in the same department.
These aren't duplicate observations.
We'll therefore rely on municipality codes, which are unique.

::: {.callout-tip}
## Exercise 3

Let's start data exploration. This involves some
data cleaning beforehand. 

1. Rename the variable `INSEE commune` to `code_insee`[^espace]. 
2. The first two digits of municipality codes are the department number.
Create a department variable `dep` in `emissions` and in `filosofi`
using the `str_sub` function from the `stringr` package[^stringr].

Let's start calculating our first descriptive statistics. 

3. Calculate total emissions by sector for each department.
Log-transform these results in an object `emissions_log`.
@fig-sample-log illustrates the structure of these emissions for 5 random
departments. 

4. Start from the `emissions` dataset.
Calculate total emissions by department and output the list
of the top 10 CO2 emitters and the 5 lowest-emitting departments.
Without doing a *merge*,
look at the characteristics of these departments (population and standard of living)

[^stringr]: The limited functionalities of the base language for text manipulation
quickly become constraining. We thus quickly move to `stringr`
even though it's not the main subject of the chapter. 
```{r}
#| code-fold: true
#| code-summary: "Solution question 1"
#| output: false
library(stringr)

emissions <- emissions %>%
  rename('code_insee' = `INSEE commune`)
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 2"
emissions <- emissions %>%
  mutate(dep = str_sub(code_insee, start = 1, end = 2))
filosofi <- filosofi %>%
  mutate(dep = str_sub(CODGEO, start = 1, end = 2))
```

```{r}
#| code-fold: true
#| code-summary: "Solution question 3"
#| label: question 3 exo 3
#| output: false
emissions_log <- emissions %>%
    group_by(dep) %>%
    summarise(across(where(is.numeric), sum, na.rm = TRUE)) %>%
    mutate(across(where(is.numeric), log))
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 4"

## Total emissions by department
emissions_dep <- emissions %>%
  mutate(total = rowSums(pick(where(is.numeric)), na.rm = TRUE)) %>%
  group_by(dep) %>%
  summarise(total = sum(total))
gros_emetteurs <- emissions_dep %>%
  arrange(desc(total)) %>%
  head(10)
petits_emetteurs <- emissions_dep %>%
  arrange(total) %>%
  head(5)

## Characteristics of these departments in filosofi
gros_emetteurs_filosofi <- filosofi %>%
  filter(dep %in% gros_emetteurs$dep) %>%
  group_by(dep) %>%
  summarise(across(c('NBPERSMENFISC16','MED16'), \(x) mean(x, na.rm = TRUE)))

head(gros_emetteurs_filosofi)
```

```{r}
#| echo: true
#| fig-cap: Emission structure of five random departments
#| label: fig-sample-log
#| code-fold: true
#| code-summary: "Code to create the figure below"

library(tidyr)
library(ggplot2)

emissions_log_sample <- emissions_log %>%
  filter(dep %in% sample(unique(dep),5))

emissions_log_sample <- emissions_log_sample %>%
  pivot_longer(cols = -dep, names_to = "Category", values_to = "Value")

ggplot(emissions_log_sample, aes(x = dep, y = Value, fill = Category)) +
    geom_bar(stat = "identity") +
    labs(x = "Department", y = "Value") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_fill_viridis_d()
```

<details>
<summary>
Example of using `str_sub`
</summary>
```r
library(stringr)
df %>% mutate(x = str_sub(y, start = 3, end = 5))
```

</details>

:::

[^espace]: The space in the variable name is annoying. To be able to
use this variable's name in `rename`, we'll need to use
backticks, i.e., ` INSEE commune `.

# Restructuring data

Two types of data are generally presented: 
    
* __wide__ format: data contains repeated observations for the same individual (or group) in different columns 
* __long__ format: data contains repeated observations for the same individual in different rows with a column to distinguish observation levels

An example of the distinction between the two can be taken from Hadley Wickham's reference work, *R for Data Science*:

![_Long_ (left) and _wide_ (right) data (source: *R for Data Science*)](https://d33wubrfki0l68.cloudfront.net/3aea19108d39606bbe49981acda07696c0c7fcd8/2de65/images/tidy-9.png)

We often need to restructure data with {{< fa brands r-project >}}
to lengthen them (_wide to long_) and widen them (_long to wide_). 
The _tidyr_ package (which belongs to the _tidyverse_) allows
these types of transformations.

The following cheat sheet will help remember which functions to apply if needed:

![](https://scienceparkstudygroup.github.io/r-lesson-based-on-ohi-data-training/img/rstudio-cheatsheet-spread-gather-sep-unite.png){width="80%" fig-align="center"}

Going from *wide* to *long* format (or vice-versa)
can be extremely practical because certain functions are more suitable for one data form or another.

Generally, *long* formats are often preferable because it's
easier to iterate over rows than columns due to
{{< fa brands r-project >}}'s vectorial nature.
This is particularly
the preferred data form for preparing graphs with `ggplot`, 
which we'll discover in the next chapter. 

:::{.callout-tip}
## Exercise 4: the _wide to long_ transformation
1. Restructure the data to *long* format to have emissions data by sector while keeping the municipality as the analysis level (be careful with other identifying variables).
2. Sum by sector and graphically represent a _barplot_[^barplot] 
3. Keep, for each department, the most polluting sector

[^barplot]: you can
directly use the helper code snippet if you're not familiar with `ggplot`
```{r}
#| code-fold: true
#| code-summary: "Solution question 1"

library(tidyr)

df_long <- emissions %>%
  pivot_longer(cols = -c(code_insee, Commune, dep),
               names_to = "secteur",
               values_to = "emissions")
```
```{r}
#| code-fold: true
#| code-summary: "Solution question 2"

df_long_summary <- df_long %>%
  group_by(secteur) %>% summarise(emissions = sum(emissions, na.rm = TRUE))
```

<details>
<summary>Graph to create for question 2</summary>

Once the `df_long_summary` _dataframe_ is created, the minimal code
to create the desired _barplot_ is:
```{r}
#| echo: true
ggplot(df_long_summary) +
  geom_bar(
    aes(y = secteur, x = emissions),
    stat ='identity'
  )
```

No need to go further for now, we'll do more
`ggplot` later. 

</details>
```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 3"
df_long_dep <- df_long %>%
  group_by(secteur, dep) %>%
  summarise(emissions = sum(emissions, na.rm = TRUE)) %>%
  arrange(desc(dep), desc(emissions)) %>%
  group_by(dep) %>%
  slice_head(n = 1)
```
```{r}
#| echo: false
head(df_long_dep)
```

:::

::: {.callout-tip}
## Exercise 5: _long to wide_

TO DO
:::

# Combining data

Information we seek is increasingly obtained from multiple data sources rather than a single database. It's becoming common to need to combine data from different sources. 

We'll focus here on the most favorable case which is when information allows exact matching of two databases (otherwise we'd be in a much more complex situation of fuzzy matching). The typical situation is matching between two data sources using an individual identifier or municipality code identifier, which is our case.

It's recommended to read [this fairly complete guide on joins with {{< fa brands r-project >}}](https://www.book.utilitr.org/03_fiches_thematiques/fiche_joindre_donnees) which also gives useful recommendations for `Python` {{< fa brands python >}}.

In common statistical language,
the terms *merge* or *join* are used interchangeably. The second term comes from `SQL` syntax and is the one rather used
when coding with `dplyr`. 

<details>

<summary>
The different types of _join_ available in `dplyr`
</summary>

![](https://rafalab.dfci.harvard.edu/dsbook/wrangling/img/joins.png){width=80%}

</details>

::: {.callout-tip}
## Exercise 6: enriching emissions data

First, we'll calculate each municipality's carbon footprint. 

1. Calculate total emissions using the following command
(since this is complex, we give it directly):
```{r}
emissions <- emissions %>%
  mutate(total = rowSums(pick(where(is.numeric)), na.rm = TRUE))
```

2. Perform a left join between emissions data and framing data[^notebiais].

[^notebiais]: Ideally, we should ensure this join doesn't
introduce bias. Indeed, since our reference years aren't necessarily identical,
there may be a _mismatch_ between our two sources. Since the tutorial is already long, we won't go down this path. Interested readers can perform such an analysis as an additional exercise.

3. Calculate carbon footprint (total emissions / population).

At this stage we might want to move toward modeling to try to explain
carbon footprint determinants from municipal variables. 
However, an inferential approach requires
checking descriptive statistics beforehand to be relevant.

4. Use the following code to output a histogram in level then in log of municipal carbon footprint;

```{r}
ggplot(emissions_merged) +
  geom_histogram(aes(x = empreinte, y = after_stat(density))) +
  scale_x_log10()
```

5. For each city, compare carbon footprint to the department median. In relative terms, which cities are particularly virtuous (i.e., those with emissions well below the department average)?

With better understanding of our data, we're approaching
inferential statistics. However, we've so far
built univariate statistics but haven't sought to understand
results by looking at the link with other variables. 
This brings us to bivariate statistics, particularly correlation analysis. 
This work is important since any subsequent modeling will consist of 
refining correlation analysis to account for cross-correlations
between multiple factors. We propose here to do this analysis
in a minimal way. 

6. Look at the correlation between framing variables and carbon footprint (the solution is given, as the manipulations aren't obvious).
Do some variables seem to potentially influence carbon footprint?
```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 1"

emissions <- emissions %>%
  mutate(total = rowSums(pick(where(is.numeric)), na.rm = TRUE))
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 2"
emissions_merged <- emissions %>%
  left_join(filosofi, by = c("code_insee" = "CODGEO"))
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 3"
emissions_merged <- emissions_merged %>%
  mutate(empreinte = total/NBPERSMENFISC16)
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 4"
ggplot(emissions_merged) +
  geom_histogram(aes(x = empreinte, y = after_stat(density))) +
  scale_x_log10()
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 5"
#| echo: true
emissions_merged <- emissions_merged %>%
  rename(departement = dep.x) %>%
  group_by(departement) %>%
  mutate(empreinte_mediane = median(empreinte, na.rm = TRUE)) %>%
  mutate(empreinte_relative = empreinte/empreinte_mediane)

emissions_merged %>% arrange(empreinte_relative)
```

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Solution question 6"

library(tibble)

correlations <- cor(
  emissions_merged %>% ungroup() %>% select(where(is.numeric)),
  use="complete.obs"
  )[,'empreinte']

correlations <- enframe(correlations) %>%
  filter(name %in% colnames(filosofi)) %>%
  arrange(desc(abs(value)))
```

Here's a quick visualization of correlations with carbon footprint:
```{r}
ggplot(correlations) + geom_bar(aes(x = value, y = name), stat = "identity") +
  scale_y_discrete(limits = correlations$name) 
```

:::